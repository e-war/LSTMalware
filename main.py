import numpy as np
import csv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow import keras
from keras.models import Sequential
from keras.layers import LSTM, Dense

## variables
include_lines = 5 # how many logs do we take from each file

hidden_units = 10
epochs = 4
batch_size = 100
##


def encode_data(data):
    # Initialize the LabelEncoder
    label_encoder = LabelEncoder()

    # Flatten and encode the data
    encoded_data = label_encoder.fit_transform(np.array(data).flatten())

    return encoded_data.reshape(data.shape)

# read labels.csv from directory, use to construct np array of all collected process within labels.csv

def retrieve_all_data(dir):
    constructed_data = []
    with open(dir+'labels.csv', newline='') as csvfile:
        reader = csv.DictReader(csvfile)
        for process in reader:
            constructed_data.append(retrieve_operation_data(dir+process['process_name']+'.CSV',process['process_name']))
    return constructed_data

# convert a single applications csv file into a usable numpy array of the process + created threads, perform this for the first x rows
def retrieve_operation_data(csv_path,process_name):
    process_operations = []
    with open(csv_path, newline='') as csvfile:
        reader = csv.DictReader(csvfile)
        child_threads = []
        for i, row in enumerate(reader):
            # we only do the first x rows
            if(i > include_lines):
                break
            # if this is monitored process or a child of this process
            if(row['Process Name'] == process_name or row['TID'] in child_threads):
                # if this thread creates a child we should follow this process as well
                if(row['Operation'] == 'Thread Create'):
                    # skips the prefix 'Thread ID: '(len=11) and just appends the thread number
                    child_threads.append(row['Detail'][11:])
                # prepare needed headers to variables
                proc_operation = row['Operation']
                proc_path = row['Image Path']
                proc_result = row['Result']
                proc_detail = row['Detail']
                proc_duration = row['Duration']
                # append operation
                process_operations.append([proc_operation,proc_path,proc_result,proc_detail,proc_duration])
    return process_operations


## testing
data = retrieve_all_data('/home/elliot/Documents/Work/uni/final_proj/datasets/sample/')
data = np.array(data)
enc_data = encode_data(data)
print(enc_data)


labels = [
    "SAFE", # prog 1
    "MALICIOUS" # prog 2
]

label_e = LabelEncoder()
enc_labels = label_e.fit_transform(labels)

x_train, x_test, y_train, y_test = train_test_split(enc_data ,enc_labels, test_size=0.2, random_state=55)

## reshape data for LSTM input

x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], -1))
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], -1))

y_train = np.asarray(y_train).astype('float32').reshape((-1,1))
y_test = np.asarray(y_test).astype('float32').reshape((-1,1))



model = Sequential()
model.add(LSTM(hidden_units,input_shape=(x_train.shape[1], x_train.shape[2])))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()
print(model.dtype)
model.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=epochs, batch_size=batch_size)
